using Beamable.Api.Autogenerated.Accounts;
using Beamable.Api.Autogenerated.Content;
using Beamable.Api.Autogenerated.Models;
using Beamable.Common.Api;
using Beamable.Common.BeamCli;
using Beamable.Common.BeamCli.Contracts;
using Beamable.Common.Content;
using Beamable.Serialization;
using Beamable.Server;
using cli.Services;
using cli.Utils;
using Newtonsoft.Json.Linq;
using System.Collections.Concurrent;
using System.Diagnostics;
using System.Runtime.CompilerServices;
using System.Security.Cryptography;
using System.Text;
using System.Text.Json;
using System.Text.Json.Nodes;
using System.Text.Json.Serialization;
using System.Text.RegularExpressions;
using System.Threading.Channels;
using static System.Threading.Tasks.Task;
using ContentDefinition = Beamable.Api.Autogenerated.Models.ContentDefinition;
using JsonConvert = Newtonsoft.Json.JsonConvert;

namespace cli.Content;

public class LocalContentFileChanges
{
	public List<ChangedContentFile> AllFileChanges;
}

public struct RemoteContentPublished
{
	public string OwnerCid;
	public string OwnerPid;
	public string PublisherAccountId;
	public string PublisherEmail;
	public string ReferenceUid;

	public ContentSyncReport AutoSyncReport;
}

public struct ChangedContentFile
{
	public string OwnerPid;
	public string OwnerManifestId;

	public string OldContentId;
	public string ContentId;

	public string FullFilePath;
	public string OldFullFilePath;

	public bool WasDeleted() => string.IsNullOrEmpty(FullFilePath) && !string.IsNullOrEmpty(OldFullFilePath);
	public bool WasCreated() => !string.IsNullOrEmpty(FullFilePath) && string.IsNullOrEmpty(OldFullFilePath);
	public bool WasRenamed() => !WasDeleted() && !WasCreated() && FullFilePath != OldFullFilePath;
	public bool WasChanged() => !WasCreated() && !WasDeleted() && FullFilePath == OldFullFilePath;
}

public class ContentService
{
	/// <summary>
	/// <see cref="PublishContent"/>
	/// </summary>
	private const int ERR_CODE_PUBLISH_FAILED_INVALID_REFERENCE_MANIFEST = 3;

	/// <summary>
	/// <see cref="CreateFakeEmptyManifest"/> and <see cref="GetManifest"/>.
	/// </summary>
	private const string FAKE_EMPTY_MANIFEST_UID = "EmptyManifest";

	private readonly CliRequester _requester;
	private readonly ConfigService _config;
	private readonly IContentApi _contentApi;
	private readonly IAccountsApi _accountsApi;

	/// <summary>
	/// We use this to ensure only one thread is ever running the <see cref="GetAllContentFiles"/> function as well as any other group of file system operations:
	///  - Writing to disk from a sync CANNOT happen in the middle of a <see cref="GetAllContentFiles"/>.
	///  - Writing to disk from a publish CANNOT happen in the middle of a <see cref="GetAllContentFiles"/>.
	/// 
	/// </summary>
	private SemaphoreSlim _fileSystemOperationSemaphore = new(1, 1);

	private readonly Channel<ChangedContentFile> _channelChangedContentFiles;
	private readonly Channel<RemoteContentPublished> _channelRemoteContentPublishes;

	private static readonly ConcurrentDictionary<string, ClientManifestJsonResponse> _cachedManifests = new();
	private static readonly ConcurrentDictionary<long, string> _cachedAccountEmails = new();

	/// <summary>
	/// We can't use these filter types before we actually load the file into memory. 
	/// </summary>
	public static readonly HashSet<ContentFilterType> UNSUPPORTED_FILTERS_BEFORE_LOADING = new() { ContentFilterType.Tags };

	public ContentService(CliRequester requester, ConfigService config, IContentApi api, IAccountsApi accountsApi)
	{
		_requester = requester;
		_config = config;
		_contentApi = api;
		_accountsApi = accountsApi;

		_channelChangedContentFiles = Channel.CreateUnbounded<ChangedContentFile>(new UnboundedChannelOptions() { SingleReader = true, SingleWriter = false, AllowSynchronousContinuations = true, });
		_channelRemoteContentPublishes = Channel.CreateUnbounded<RemoteContentPublished>(new UnboundedChannelOptions() { SingleReader = true, SingleWriter = false, AllowSynchronousContinuations = true, });
	}

	private string RootContentPath => Path.Combine(_config.ConfigDirectoryPath!, Constants.CONTENT_DIRECTORY);

	private IEnumerable<string> GetPidsWithCachedLocalContent() => Directory.EnumerateDirectories(RootContentPath);
	private string GetCacheKeyForManifest(string cid, string pid, string manifestId, string manifestUid) => $"{cid}₢{pid}₢{manifestId}₢{manifestUid}";
	private string GetCacheKeyForLatestManifest(string cid, string pid, string manifestId) => $"{cid}₢{pid}₢{manifestId}₢";

	public string EnsureContentPathForRealmExists(out bool created, string pid, string manifest = "global")
	{
		created = false;

		var path = Path.Combine(RootContentPath, pid, manifest);
		if (!Directory.Exists(path))
		{
			Directory.CreateDirectory(path);
			created = true;
		}

		return path;
	}

	public async Task ReplaceLocalContent(string contentDirectory, string sourcePath, string destinationPath)
	{
		Debug.Assert(Directory.Exists(contentDirectory), "If you see this, please make sure that your content directory is created.");

		Debug.Assert(Directory.Exists(sourcePath), $"Your source directory [{sourcePath}] doesn't exist. Please make sure that your realm PID is correct and try again.");

		// Create the destination folder if it doesn't exist.
		if (!string.IsNullOrEmpty(destinationPath) && !Directory.Exists(destinationPath))
		{
			Directory.CreateDirectory(destinationPath);
		}

		var manifest = await GetManifest();
		
		string[] destinationFiles = Directory.GetFiles(destinationPath, "*", SearchOption.AllDirectories);

		foreach (string filePath in destinationFiles)
		{
			File.Delete(filePath);
		}

		string[] sourceFiles = Directory.GetFiles(sourcePath, "*", SearchOption.AllDirectories);

		// Copy file to the target path
		foreach (string filePath in sourceFiles)
		{
			string relativePath = Path.GetRelativePath(sourcePath, filePath);
			string destinationFilePath = Path.Combine(destinationPath, relativePath);

			string fileName = Path.GetFileName(destinationFilePath);

			string directoryPath = destinationFilePath.Replace(fileName, string.Empty);

			if (!Directory.Exists(directoryPath))
			{
				Directory.CreateDirectory(directoryPath);
			}
			
			string fileJson = await File.ReadAllTextAsync(filePath);
			JObject jsonObj = JObject.Parse(fileJson);

			jsonObj[ContentFile.JSON_NAME_REFERENCE_MANIFEST_ID] = manifest.uid.Value;
			
			await File.WriteAllTextAsync(destinationFilePath, jsonObj.ToString());
		}
		
		
	}

	private Dictionary<(string pid, string manifest), FileSystemWatcher> _watchers = new();

	public async IAsyncEnumerable<LocalContentFileChanges> ListenToLocalContentFileChanges(string pid, string manifestId = "global", [EnumeratorCancellation] CancellationToken token = default)
	{
		// The caller of this function must ensure that a reset has happened at least once in this realm (hence the assert)
		var contentFolder = EnsureContentPathForRealmExists(out var created, _requester.Pid, manifestId);
		Debug.Assert(!created, "This should never happen. If does, this is a bug --- please report it to Beamable.");

		_watchers.Add((pid, manifestId), new FileSystemWatcher());

		// We need to keep track of the last write time for each content file in order to disambiguate multiple events firing simultaneously for the same file.
		// For example, on Windows, a Created event is always fired alongside a Changed event of the same file (because of "reasons", I guess)
		// This dictionary helps us fire off only one relevant event at a time even when the file watcher gets confused about the desireable semantics...
		var eventDisambiguationHelper = new Dictionary<string, long>();
		
		// Set up the file watcher...
		var watcher = _watchers[(pid, manifestId)];
		watcher.BeginInit();
		watcher.Path = contentFolder;
		watcher.IncludeSubdirectories = true;
		watcher.Filter = "*.json";
		watcher.EnableRaisingEvents = true;
		watcher.NotifyFilter = (NotifyFilters.Attributes |
		                        NotifyFilters.CreationTime |
		                        NotifyFilters.DirectoryName |
		                        NotifyFilters.FileName |
		                        NotifyFilters.LastWrite);
		watcher.Error += (_, e) => Log.Error(e.GetException().ToString());
		watcher.Disposed += (_, e) => Log.Error($"Disposed {e}");
		watcher.Created += (_, e) => { OnLocalRealmContentFilesChanged(e); };
		watcher.Deleted += (_, e) => { OnLocalRealmContentFilesChanged(e); };
		watcher.Renamed += (_, e) => { OnLocalRealmContentFilesChanged(e); };
		watcher.Changed += (_, e) => { OnLocalRealmContentFilesChanged(e); };
		watcher.EndInit();

		// Keep waiting for messages from the set up file watcher.
		var reader = _channelChangedContentFiles.Reader;

		while (await reader.WaitToReadAsync(token))
		{
			// If the operation was cancelled, we break out.
			if (token.IsCancellationRequested)
			{
				break;
			}
			
			// For the case which multiple files are edited at the same time, the watcher triggers one message for each one.
			// So to batch it together we wait 100 ms and then try to read from the buffer.
			await Delay(100, token);
			
			// Get all the files that were changed respecting the PID filter.
			var batchedChanges = new LocalContentFileChanges() { AllFileChanges = new() };
			while (reader.TryRead(out var changed))
			{
				if (changed.OwnerPid == pid)
				{
					batchedChanges.AllFileChanges.Add(changed);
				}
			}

			yield return batchedChanges;
		}

		yield break;

		void OnLocalRealmContentFilesChanged(FileSystemEventArgs e)
		{
			var lastWriteTime = File.GetLastWriteTime(e.FullPath).ToFileTimeUtc();
			if (e.ChangeType == WatcherChangeTypes.Created)
			{
				var changedContent = new ChangedContentFile { OwnerPid = pid };
				changedContent.OwnerPid = pid;
				changedContent.OwnerManifestId = manifestId;

				changedContent.ContentId = Path.GetFileNameWithoutExtension(e.Name);
				changedContent.FullFilePath = e.FullPath;
				changedContent.OldContentId = "";
				changedContent.OldFullFilePath = "";

				if (!eventDisambiguationHelper.TryGetValue(e.FullPath, out var time) || time != lastWriteTime)
				{
					eventDisambiguationHelper[e.FullPath] = lastWriteTime;
					Log.Verbose($"Created file ({lastWriteTime}): {JsonConvert.SerializeObject(changedContent)} ");
					_channelChangedContentFiles.Writer.TryWrite(changedContent);
				}
			}
			else if (e.ChangeType == WatcherChangeTypes.Deleted)
			{
				var changedContent = new ChangedContentFile { OwnerPid = pid };
				changedContent.OwnerPid = pid;
				changedContent.OwnerManifestId = manifestId;

				changedContent.ContentId = changedContent.OldContentId = Path.GetFileNameWithoutExtension(e.Name);
				changedContent.FullFilePath = "";
				changedContent.OldFullFilePath = e.FullPath;
				Log.Verbose($"Deleted file: {JsonConvert.SerializeObject(changedContent)} ");
				_channelChangedContentFiles.Writer.TryWrite(changedContent);
			}
			else if (e.ChangeType == WatcherChangeTypes.Changed)
			{
				var changedContent = new ChangedContentFile { OwnerPid = pid };
				changedContent.OwnerPid = pid;
				changedContent.OwnerManifestId = manifestId;
				changedContent.ContentId = changedContent.OldContentId = Path.GetFileNameWithoutExtension(e.Name);
				changedContent.FullFilePath = changedContent.OldFullFilePath = e.FullPath;

				if (!eventDisambiguationHelper.TryGetValue(e.FullPath, out var time) || time != lastWriteTime)
				{
					eventDisambiguationHelper[e.FullPath] = lastWriteTime;
					Log.Verbose($"Changed file ({lastWriteTime}): {JsonConvert.SerializeObject(changedContent)} ");
					_channelChangedContentFiles.Writer.TryWrite(changedContent);
				}
			}
			else if (e.ChangeType == WatcherChangeTypes.Renamed)
			{
				if (e is RenamedEventArgs renamedEventArgs)
				{
					var renamedContent = new ChangedContentFile();
					renamedContent.OwnerPid = pid;
					renamedContent.OwnerManifestId = manifestId;
					renamedContent.ContentId = Path.GetFileNameWithoutExtension(renamedEventArgs.Name);
					renamedContent.FullFilePath = renamedEventArgs.FullPath;
					renamedContent.OldContentId = Path.GetFileNameWithoutExtension(renamedEventArgs.OldName);
					renamedContent.OldFullFilePath = renamedEventArgs.OldFullPath;
					Log.Verbose($"Renamed file: {JsonConvert.SerializeObject(renamedContent)} ");

					_channelChangedContentFiles.Writer.TryWrite(renamedContent);
				}
			}
		}
	}

	public async IAsyncEnumerable<RemoteContentPublished> ListenToRemoteContentPublishes(CommandArgs args, string manifestId = "global", [EnumeratorCancellation] CancellationToken token = default)
	{
		// Subscribe to the content refresh notification for the realm we are targeting.
		var listenTask = Run(async () =>
		{
			try
			{
				var handle = WebsocketUtil.ConfigureWebSocketForServerNotifications(args, new[] { "content.manifest" }, token);
				await WebsocketUtil.RunServerNotificationListenLoop(handle, message =>
				{
					Log.Verbose("Received Content Publish Notification");
					Run(async () => await OnContentPublished(message.body, args.Lifecycle), token);
				}, token);
			}
			catch (Exception e)
			{
				Console.WriteLine(e);
				throw;
			}
		}, token);

		// Loop while we are listing to the published changes on this realm and emit an event out of this enumerable every time we get one. 
		var reader = _channelRemoteContentPublishes.Reader;
		while (await reader.WaitToReadAsync(token) && !token.IsCancellationRequested)
		{
			// Break if a cancellation request came in.
			if (token.IsCancellationRequested)
				break;

			// Get all the files that were changed respecting the PID filter.
			while (reader.TryRead(out var changed))
			{
				yield return changed;
			}
		}

		await listenTask;

		yield break;

		async Task OnContentPublished(object o, AppLifecycle lifecycle)
		{
			Log.Verbose("Responding to Content Publish Notification");
			var payload = (JObject)o;
			var categories = payload.Property("categories")!.Value.Values<string>().ToArray();
			var manifestInfo = payload.Property("manifest")!.Value.ToObject<JObject>();

			var publishedManifestId = manifestInfo.Property("id")!.Value.ToObject<string>();
			var manifestUid = manifestInfo.Property("uid")!.Value.ToObject<string>();
			var manifestChecksum = manifestInfo.Property("checksum")!.Value.ToObject<string>();
			var createdTimestamp = manifestInfo.Property("created")!.Value.ToObject<long>();
			var publisherAccountId = manifestInfo.Property("publisherAccountId")!.Value.ToObject<long>();


			// We only emit an event if the published manifest matches the id we care about.
			if (manifestId == publishedManifestId)
			{
				Log.Verbose("Fetching Manifest Data. MANIFEST_ID={0}, UID={1}", manifestId, manifestUid);
				var emailFetchTask = GetAccountEmail(publisherAccountId);
				var manifestFetchTask = GetManifest(publishedManifestId, manifestUid, replaceLatest: true);

				var email = await emailFetchTask;
				var newManifest = await manifestFetchTask;

				Log.Verbose("Found Email for Publisher. MANIFEST_ID={0}, EMAIL={1}", manifestId, email);
				Log.Verbose("Found New Published Manifest. MANIFEST_ID={0}, UID={1}", manifestId, manifestFetchTask.Result.uid.GetOrElse(""));

				// Let's sync the local content without synching created or modified files and ignoring conflicts.
				Log.Verbose("Sync'ing manifest. MANIFEST_ID={0}, UID={1}", manifestId, manifestFetchTask.Result.uid.GetOrElse(""));
				try
				{
					var syncReport = await SyncLocalContent(lifecycle, newManifest, manifestId, syncCreated: false, syncModified: false, forceSyncConflicts: false, syncDeleted: false);

					// Put this on the channel so it gets picked up below.
					_channelRemoteContentPublishes.Writer.TryWrite(new RemoteContentPublished()
					{
						OwnerCid = _requester.Cid,
						OwnerPid = _requester.Pid,
						PublisherAccountId = publisherAccountId.ToString(),
						PublisherEmail = email,
						AutoSyncReport = syncReport,
						ReferenceUid = manifestUid,
					});
				}
				catch (Exception e)
				{
					if (e is AggregateException ae)
					{
						foreach (var aeInnerException in ae.InnerExceptions)
						{
							Log.Error(aeInnerException, "Error when auto-sync'ing when publishing");
						}
					}

					throw;
				}

				Log.Verbose("Sync'ed manifest. Sending out event. MANIFEST_ID={0}, UID={1}", manifestId, manifestFetchTask.Result.uid.GetOrElse(""));
			}
		}
	}

	/// <summary>
	/// Returns the list of <see cref="ContentFile"/> relative to the given manifest.
	/// If no manifest is provided, we'll fetch it with the given <paramref name="manifestId"/>.
	/// If you provide a manifest, please make sure the <paramref name="manifestId"/> matches the given manifest.
	///
	/// The list of content files is a union (by content id) of:
	/// - Each content in the <paramref name="latestManifest"/>.
	/// - Each content file existent locally.
	///
	/// This means that it'll contain created, deleted, modified and up-to-date content alike.
	/// It gives you a full picture of the local content files relative to the given <paramref name="latestManifest"/>.
	///
	/// When <paramref name="getLocalStateOnly"/> is set, the resulting <see cref="ContentFile.ReferenceContent"/> will be empty and
	/// the <see cref="LocalContentFiles.ContentFiles"/> will ONLY contain the files that exist locally. In this case, the <see cref="ContentFile.GetStatus"/> is NOT semantically correct.
	/// As in, you can't use its value for anything.
	///
	/// If this is ever called on a manifest/realm combination for which we have no local folder, we will synchronize that folder with that realm's latest manifest before computing the <see cref="LocalContentFiles"/>.
	/// This ONLY happens if <paramref name="getLocalStateOnly"/> is false. 
	/// </summary>
	public async Task<LocalContentFiles> GetAllContentFiles(ClientManifestJsonResponse latestManifest = null, string manifestId = "global",
		ContentFilterType filterType = ContentFilterType.ExactIds, string[] filters = null,
		bool getLocalStateOnly = false,
		bool allowAutoSyncModified = false,
		bool allowAutoSyncDeleted = false)
	{
		filters ??= Array.Empty<string>();

		// Let's wait if some other function in this class is reading/writing to disk
		await _fileSystemOperationSemaphore.WaitAsync();

		// Initialize the local files
		var localFiles = new LocalContentFiles() { ManifestId = manifestId, TargetManifest = latestManifest, ContentFiles = new(1024), };

		// If no reference manifest was provided, let's fetch the latest Manifest.
		if (!getLocalStateOnly)
		{
			localFiles.TargetManifest ??= await GetManifest(manifestId);
		}
		else
		{
			// Try to get it from the cached manifests
			localFiles.TargetManifest ??= await GetManifest(manifestId, cachedOnly: true);

			// Create an empty one.
			localFiles.TargetManifest ??= new() { entries = Array.Empty<ClientContentInfoJson>(), };
		}

		// Whenever we try to get the local state in relation to the remote one --- if we had never sync'ed before, we do a sync before computing the state. 
		var contentFolder = EnsureContentPathForRealmExists(out _, _requester.Pid, manifestId);

		// We get a filter function --- we only filter before loading IF we can.
		// Otherwise, we filter after we finish loading the file contents into memory
		Func<ContentFile, bool> filterFunc = _ => true;
		if (!UNSUPPORTED_FILTERS_BEFORE_LOADING.Contains(filterType))
			filterFunc = BuildFilterFunc(filterType, filters);

		// Build a list of tasks for computing a ContentFile structure for each relevant content id in this manifest.  
		var tasks =
			// For each existing file inside the content folder we care about, we'll have one entry.
			Directory.EnumerateFiles(contentFolder)
				// Filter all content to only match the ones we care about.
				.Where(fp => filterFunc(new ContentFile() { Id = Path.GetFileNameWithoutExtension(fp) }))
				// Load the files that passed the filter into memory
				.Select(async fp =>
				{
					// We got to do this so that we don't collide with other software editing the files on disk. 
					var text = "";
					var readText = false;
					while (!readText || text == "")
					{
						try
						{
							text = await File.ReadAllTextAsync(fp);
							readText = true;
						}
						catch (IOException)
						{
							readText = false;
							text = "";
						}
					}

					var json = JsonSerializer.Deserialize<JsonElement>(text, GetContentFileSerializationOptions());

					var id = Path.GetFileNameWithoutExtension(fp);
					var referenceContent = localFiles.TargetManifest.entries.FirstOrDefault(e => e.contentId == id);
					var properties = json.GetProperty(ContentFile.JSON_NAME_PROPERTIES);
					var contentFile = new ContentFile()
					{
						Id = id,
						LocalFilePath = fp,
						Properties = properties,
						Tags = json.GetProperty(ContentFile.JSON_NAME_TAGS),
						FetchedFromManifestUid = json.GetProperty(ContentFile.JSON_NAME_REFERENCE_MANIFEST_ID).GetString(),
						ReferenceContent = referenceContent,
					};
					SortContentProperties(ref contentFile);
					contentFile.PropertiesChecksum = CalculateChecksum(in contentFile);

					return contentFile;
				})
				// We'll also have on entry for each entry in the reference manifest that is NOT represented in the local files.
				.Concat(
					localFiles.TargetManifest.entries
						// Filter only the content types that do NOT exist locally
						.Where(e =>
						{
							var expectedPath = Path.Combine(contentFolder, $"{e.contentId}.json");
							return !File.Exists(expectedPath);
						})
						// Filter all content to only match the ones we care about.
						.Where(fp => filterFunc(new ContentFile() { Id = fp.contentId }))
						// Create a dummy ContentFile to represent the deleted file.
						.Select(e => FromResult(new ContentFile()
						{
							Id = e.contentId,
							LocalFilePath = "",
							Properties = JsonSerializer.Deserialize<JsonElement>("{}"),
							Tags = JsonSerializer.SerializeToElement(e.tags),

							// For deletions, this is set as the reference manifest because it doesn't matter what the reference manifest was before deletion.
							// If someone publishes a manifest that has this guy in it, we'll auto sync it back up.
							// Using the target manifest uid, simplifies other cases (such as the initial sync) so we use this. 
							FetchedFromManifestUid = localFiles.TargetManifest.uid.GetOrElse(""),
							PropertiesChecksum = e.version,
							ReferenceContent = e,
						}))
				).ToList();

		// Wait for all the content file tasks and return the list of ContentFile.
		try
		{
			localFiles.ContentFiles = (await WhenAll(tasks)).ToList();

			// Filter after we've loaded the files into memory as the provided filter type can only be applied
			// over the data IN the file. 
			if (UNSUPPORTED_FILTERS_BEFORE_LOADING.Contains(filterType))
				FilterLocalContentFiles(ref localFiles, filters, filterType);

			// Gather all the distinct reference manifests.
			localFiles.ReferenceManifestUids = localFiles.ContentFiles.Select(c => c.FetchedFromManifestUid).ToHashSet();

			// Fetch all the different reference manifests in parallel if we want not only the local state
			if (!getLocalStateOnly)
			{
				var allRefsPromises = localFiles.ReferenceManifestUids.Select(rm => GetManifest(manifestId, rm)).ToArray();
				localFiles.ReferenceManifests = (await WhenAll(allRefsPromises)).ToDictionary(g => g.uid.Value, g => g);

				// Compute conflicts and update the state of the local file
				ComputeCorrectSyncOp(localFiles, allowAutoSyncModified, allowAutoSyncDeleted, out var conflicts, out var autoSync, out var updateReference);
				for (int i = 0; i < localFiles.ContentFiles.Count; i++)
				{
					ContentFile localFilesContentFile = localFiles.ContentFiles[i];
					localFilesContentFile.IsInConflict = conflicts.Contains(localFilesContentFile.Id);
					localFilesContentFile.CanAutoSync = autoSync.Contains(localFilesContentFile.Id);
					localFilesContentFile.CanUpdateReferenceWithTarget = updateReference.Contains(localFilesContentFile.Id);

					localFiles.ContentFiles[i] = localFilesContentFile;
				}
			}

			localFiles.PerIdContentFiles = localFiles.ContentFiles.ToDictionary(g => g.Id, g => g);
			return localFiles;
		}
		catch (Exception e)
		{
			if (e is AggregateException ae)
			{
				foreach (var aeInnerException in ae.InnerExceptions)
				{
					Log.Error(aeInnerException, "Error when loading content file");
				}
			}

			throw;
		}
		finally
		{
			_fileSystemOperationSemaphore.Release();
		}
	}

	/// <summary>
	/// Saves the given <paramref name="contentIds"/> with the given <paramref name="contentProperties"/> JSON-blobs.
	///
	/// If the file does not exist locally, it'll be created.
	/// In the creation case, this CANNOT be called with an empty <see cref="LocalContentFiles.TargetManifest"/>.
	/// So... for creation, always use <see cref="GetAllContentFiles"/>'s 'getLocalStateOnly == false' when generating the <see cref="LocalContentFiles"/> instance.
	///
	/// For updates of existing files, there are no restrictions. 
	/// </summary>
	public async Task BulkSaveLocalContent(LocalContentFiles localCache, string[] contentIds, string[] contentProperties)
	{
		var createdOrUpdatedDocs = new List<ContentFile>(contentIds.Length);
		for (int i = 0; i < contentIds.Length; i++)
		{
			// This command does not create new content objects; so, we check if the given id already exists before proceeding.
			string id = contentIds[i];
			var newProperties = contentProperties[i];

			if (!localCache.PerIdContentFiles.TryGetValue(id, out ContentFile file))
			{
				file = new ContentFile();
				file.Id = id;
				file.LocalFilePath = GetPathForContentId(id, localCache.ManifestId);
				file.FetchedFromManifestUid = localCache.TargetManifest.uid.GetOrElse("");
				file.ReferenceContent = null;
				file.Tags = JsonSerializer.SerializeToElement(Array.Empty<string>(), GetContentFileSerializationOptions());
			}

			// Make sure this is serialized properly and sorted
			var newPropsJson = JsonSerializer.Deserialize<JsonElement>(newProperties);
			newPropsJson = JsonSerializer.SerializeToElement(newPropsJson, GetContentFileSerializationOptions());

			// Set this as the new JsonElement for the content file.
			file.Properties = newPropsJson;
			file.PropertiesChecksum = CalculateChecksum(file);

			// Store the content file
			createdOrUpdatedDocs.Add(file);
		}

		// Save the actual created or updated content
		await _fileSystemOperationSemaphore.WaitAsync();
		try
		{
			var contentFolder = EnsureContentPathForRealmExists(out _, _requester.Pid, localCache.ManifestId);
			var updateTasks = createdOrUpdatedDocs.Select(d => SaveContentFile(contentFolder, d));
			await WhenAll(updateTasks);
		}
		catch (Exception e)
		{
			var err = $"Failed to save Content. Errors:{e.Message}";
			throw new CliException(err, 5, true);
		}
		finally
		{
			_fileSystemOperationSemaphore.Release();
		}
	}

	/// <summary>
	/// Publishes the local changes made to the given <paramref name="manifestId"/> to the current <see cref="IAppContext.Pid"/>.
	///
	/// First, this checks if the last manifest we pulled is the same as the last manifest anyone published to that realm.
	/// If it isn't we error out with <see cref="ERR_CODE_PUBLISH_FAILED_INVALID_REFERENCE_MANIFEST"/>.
	///
	/// For now, users cannot publish UNLESS they make their changes against the latest published manifest.
	/// </summary>
	public async Task PublishContent(AppLifecycle lifecycle, string manifestId = "global", Action<ContentProgressUpdateData> onProgressUpdateAction = null)
	{
		// Get the latest manifest id and generate the diff against local files. 
		var latestManifest = await GetManifest(manifestId);
		var localAgainstLatest = await GetAllContentFiles(latestManifest, manifestId);

		// If we have any conflicting modifications over the latest remote manifest, let's block the publish.  
		if (localAgainstLatest.ContentFiles.Any(c => c.IsInConflict))
		{
			var conflicted = localAgainstLatest.ContentFiles.Where(c => c.IsInConflict).Select(c => c.Id);
			throw new CliException(
				"You have conflicting changes that were made against an older manifest. " +
				$"Please run `dotnet beam content sync --force --filters {string.Join(",", conflicted)}` (this will discard all your local changes for the conflicting files)." +
				$"If you'd like, you can then re-apply your local ones before publishing. ",
				ERR_CODE_PUBLISH_FAILED_INVALID_REFERENCE_MANIFEST, true);
		}

		// Now, we compute our status against the latest manifest and get ONLY the files that weren't deleted (these are the ones that will be included in the new manifest).
		var changedContents = localAgainstLatest.ContentFiles
			.Where(c => !c.GetStatus().HasFlag(ContentStatus.Deleted))
			.Select(c =>
			{
				// Build the properties from the local data.
				var properties = new MapOfContentMeta();
				foreach (var prop in c.Properties.EnumerateObject())
				{
					var key = prop.Name;
					var val = prop.Value;

					var meta = new ContentMeta();
					if (val.TryGetProperty(nameof(ContentMeta.data), out var dataProp))
						meta.data = new OptionalJsonString(JsonString.FromJson(dataProp.GetRawText()));

					if (val.TryGetProperty(nameof(ContentMeta.text), out var textProp))
						meta.text = OptionalString.FromString(textProp.GetString());

					if (val.TryGetProperty("$link", out var linkProp) || val.TryGetProperty("link", out linkProp))
						meta.Link = OptionalString.FromString(linkProp.GetString());

					if (val.TryGetProperty("$links", out var linksProp) || val.TryGetProperty("links", out linksProp))
						meta.Links = new OptionalArrayOfString(linksProp.EnumerateArray().Select(j => j.GetString()));

					properties.Add(key, meta);
				}

				// Build the tags from the local data.
				var tags = new OptionalArrayOfString(c.Tags.EnumerateArray().Select(j => j.GetString()).ToArray());

				// Return the built content definition
				return new ContentDefinition
				{
					id = c.Id,
					checksum = c.PropertiesChecksum,
					properties = properties,
					tags = tags,

					// This is not really supported anymore so ignore it.
					// TODO: Investigate this with Ben or Ali to figure out if/when we can kill it.
					variants = null,
				};
			}).ToArray();

		var batches = changedContents.Chunk(CliConstants.CONTENT_PUBLISH_BATCH_SIZE);
		// Then we save them to S3
		Func<Task<SaveContentResponse>>[] saveContentRequestsTasks = batches.Select(contentDefinitions =>
			(Func<Task<SaveContentResponse>>)(async () =>
		{
			var contentProgressUpdateData = new ContentProgressUpdateData()
			{
				contentName = string.Join(", ", contentDefinitions.Select(item => item.id)),
				totalItems = changedContents.Length,
			};
			
			var saveRequest = new SaveContentRequest() { content = contentDefinitions };
			SaveContentResponse saveResponse;
			try
			{
				saveResponse = await _contentApi.Post(saveRequest);
			}
			catch (Exception exception)
			{
				contentProgressUpdateData.EventType = ContentProgressUpdateData.EVT_TYPE_SyncError;
				contentProgressUpdateData.errorMessage = exception.Message;
				onProgressUpdateAction?.Invoke(contentProgressUpdateData);
				throw;
			}
			

			contentProgressUpdateData.EventType = ContentProgressUpdateData.EVT_TYPE_PublishComplete;
			onProgressUpdateAction?.Invoke(contentProgressUpdateData);
			return saveResponse;
		})).ToArray();

		SaveContentResponse[] saveContentResponses = new SaveContentResponse[saveContentRequestsTasks.Length];
		try
		{
			for (int index = 0; index < saveContentRequestsTasks.Length; index++)
			{
				if (lifecycle.IsCancelled)
				{
					throw new CliException($"Publish operation is cancelled.");
				}
				saveContentResponses[index] = await saveContentRequestsTasks[index]();
				var updateProcessedItems = new ContentProgressUpdateData()
				{
					totalItems = changedContents.Length,
					processedItems = (index + 1) * CliConstants.CONTENT_PUBLISH_BATCH_SIZE,
					EventType = ContentProgressUpdateData.EVT_TYPE_UpdateProcessedItemCount
				};
				onProgressUpdateAction?.Invoke(updateProcessedItems);
			}
		}
		catch (Exception e)
		{
			// Handle failure case by just stopping here and erroring out
			throw new CliException($"Failed to save the local content. Please try again. EXCEPTION={e.Data}");
			
		}
		
		// Prepare the save manifest request using the response from the save content request.
		var saveManifestRequest = new SaveManifestRequest
		{
			// Manifest ID
			id = manifestId,

			// This is just a type-conversion
			references = saveContentResponses.SelectMany(contentDefinition => contentDefinition.content).Select(c =>
				new ReferenceSuperset
				{
					id = c.id,
					version = c.version,
					checksum = c.checksum,
					type = c.type.ToString().ToLower(),
					tags = new OptionalArrayOfString(c.tags),
					uri = c.id,
					visibility = c.visibility.ToString().ToLower()
				}).ToArray()
		};
		
		if (lifecycle.IsCancelled)
		{
			throw new CliException($"Publish operation is cancelled.");
		}
		
		foreach (ReferenceSuperset referenceSuperset in saveManifestRequest.references)
		{
			Log.Information($"Saving manifest {referenceSuperset.id} - {referenceSuperset.visibility.Value} - {referenceSuperset.version}");
		}
		
		// Update the local reference manifest
		try
		{
			_ = await _contentApi.PostManifest(saveManifestRequest);
		}
		catch (RequesterException e)
		{
			Log.Information(e.RequestError.error);
			throw;
		}
	}

	/// <summary>
	/// Compares the local state of each <see cref="ContentFile"/> to the given <paramref name="referenceManifestUid"/> and resets the local file content to whatever that content was at that version.
	/// If no <paramref name="referenceManifestUid"/> is provided, it'll use whatever is stored at <see cref="LocalContentConfig.LatestManifestDownloaded"/> for determining the <see cref="ContentFile.GetStatus"/> results.
	///
	/// The filters are applied in accordance to <see cref="ContentFilterType"/>'s semantics.
	/// When <paramref name="deleteCreated"/> is true, this will ALSO delete any local only files.
	/// </summary>
	public async Task<ContentSyncReport> SyncLocalContent(AppLifecycle lifecycle, string manifestId,
		ContentFilterType filterType = ContentFilterType.ExactIds, string[] filters = null,
		bool deleteCreated = true, bool syncModified = true, bool forceSyncConflicts = true, bool syncDeleted = true,
		string referenceManifestUid = "", Action<ContentProgressUpdateData> onContentSyncProgressUpdate = null)
	{
		var targetManifest = await GetManifest(manifestId, referenceManifestUid, replaceLatest: string.IsNullOrEmpty(referenceManifestUid));
		return await SyncLocalContent(lifecycle, targetManifest, manifestId, filterType, filters, deleteCreated, syncModified, forceSyncConflicts, syncDeleted, onContentSyncProgressUpdate);
	}

	/// <summary>
	/// <inheritdoc cref="SyncLocalContent(string,string[],ContentFilterType,bool,string)"/>
	/// </summary>
	public async Task<ContentSyncReport> SyncLocalContent(AppLifecycle lifecycle, ClientManifestJsonResponse targetManifest, string manifestId,
		ContentFilterType filterType = ContentFilterType.ExactIds, string[] filters = null,
		bool syncCreated = true, bool syncModified = true, bool forceSyncConflicts = true, bool syncDeleted = true, 
		Action<ContentProgressUpdateData> onContentSyncProgressUpdate = null)
	{
		var report = new ContentSyncReport();
		report.ManifestId = manifestId;
		filters ??= Array.Empty<string>();

		// Load up all the content files for this pid and filter them accordingly.
		var targetManifestUid = targetManifest.uid.GetOrElse("");

		// Fetch our local state relative to the new target manfest.
		// We either filter after we load into memory OR before, based on whether that's possible.
		var localContentRelativeToNewManifest = await GetAllContentFiles(targetManifest, manifestId, filterType, filters, allowAutoSyncModified: syncModified, allowAutoSyncDeleted: syncDeleted);

		// Get the list of modified and deleted content to re-download from the target manfiest
		// If given a list of content ids, will ONLY download the given ids
		// When ignore conflicts is true, we won't download content that is currently in conflict.
		var contentToDownload = localContentRelativeToNewManifest.ContentFiles
			.Where(c => forceSyncConflicts ? c.IsInConflict || c.CanAutoSync : c.CanAutoSync)
			.ToArray();

		// Get the list of created content we need to delete (if requested).
		var contentToDelete = localContentRelativeToNewManifest.ContentFiles
			.Where(c => syncCreated && c.GetStatus().HasFlag(ContentStatus.Created))
			.ToArray();

		// Get the list of content that is up-to-date but the referenceManifestUid is not pointing at the latest one (so we can update the reference).
		var contentToUpdateManifestReference = localContentRelativeToNewManifest.ContentFiles
			.Where(c => c.CanUpdateReferenceWithTarget)
			.ToArray();

		// Update our sync report with what we intended to do
		report.ConflictingContents = localContentRelativeToNewManifest.ContentFiles.Where(c => c.IsInConflict).Select(c => c.Id).ToArray();
		report.AutoSynchedContents = localContentRelativeToNewManifest.ContentFiles.Where(c => c.CanAutoSync).Select(c => c.Id).ToArray();
		report.ReferenceUpdatedContents = localContentRelativeToNewManifest.ContentFiles.Where(c => c.CanUpdateReferenceWithTarget).Select(c => c.Id).ToArray();
		report.DeletedCreatedContents = contentToDelete.Where(c => !c.GetStatus().HasFlag(ContentStatus.Created)).Select(c => c.Id).ToArray();

		
		// Download and overwrite the local content for things that have changed based on the hash or don't exist.
		int totalItems = contentToDownload.Length + contentToDelete.Length;
		var downloadPromises = contentToDownload.Select(c => 
			(Func<Task<(ContentFile, JsonElement)>>)(async () =>
		{
			
			Log.Verbose("Downloading content with id. ID={Id}", c.Id);
			
			ContentProgressUpdateData contentProgress = new ContentProgressUpdateData
			{
				totalItems = totalItems, 
				contentName = c.Id
			};

			JsonElement customRequest;
			try
			{
				customRequest =await _requester.CustomRequest(Method.GET, c.ReferenceContent.uri,
					parser: s => JsonSerializer.Deserialize<JsonElement>(s));
			}
			catch (HttpRequesterException exception)
			{
				contentProgress.EventType = ContentProgressUpdateData.EVT_TYPE_SyncError;
				contentProgress.errorMessage = exception.Message;
				onContentSyncProgressUpdate?.Invoke(contentProgress);
				throw;
			}

			contentProgress.EventType = ContentProgressUpdateData.EVT_TYPE_SyncComplete;
			onContentSyncProgressUpdate?.Invoke(contentProgress);
			return (
				localContent: c,
				downloadedContent: customRequest
			);
		})).ToArray();

		// Let's try to download all the content paired with the local ContentFile representation.
		List<(ContentFile localContent, JsonElement downloadedContent)> downloadedContent = new();
		
		var batches = downloadPromises.Chunk(CliConstants.CONTENT_SYNC_BATCH_SIZE).ToArray();
		try
		{
			for (int index = 0; index < batches.Length; index++)
			{
				if (lifecycle.IsCancelled)
				{
					throw new CliException($"Sync operation is cancelled.");
				}
				
				Func<Task<(ContentFile, JsonElement)>>[] batch = batches[index];
				var items = await WhenAll(batch.Select(item => item()));
				downloadedContent.AddRange(items);
				var updateProcessedItems = new ContentProgressUpdateData()
				{
					totalItems = downloadPromises.Length,
					processedItems = (index + 1) * CliConstants.CONTENT_SYNC_BATCH_SIZE,
					EventType = ContentProgressUpdateData.EVT_TYPE_UpdateProcessedItemCount
				};
				onContentSyncProgressUpdate?.Invoke(updateProcessedItems);
			}
		}
		catch (Exception e)
		{
			// Let's just print out all the exceptions
			if (e is AggregateException ae)
			{
				foreach (var aeInnerException in ae.InnerExceptions)
				{
					Log.Error(aeInnerException, "Error when downloading content file");
				}
			}
			else
			{
				Log.Error(e, $"Error when downloading content files. EXCEPTION={e}");
			}

			throw;
		}

		// Makes sure the content folder for the current realm exists.
		// The caller of this function must ensure that a reset has happened at least once in this realm (hence the assert)
		var contentFolder = EnsureContentPathForRealmExists(out var created, _requester.Pid, manifestId);
		Debug.Assert(!created, "This should never happen. If does, this is a bug --- please report it to Beamable.");

		// Save the downloaded content to disk (this is locked by this semaphore so it doesn't interfere with other function calls that might be triggered simultaneously).
		await _fileSystemOperationSemaphore.WaitAsync();

		var archiveFolder = $"{contentFolder}_archive";
		Directory.CreateDirectory(archiveFolder);
		async Task ReturnArchivedFilesToManifest()
		{
			lifecycle.ShouldWaitForCancel = true;
			try
			{
				string[][] returnBatches = Directory.GetFiles(archiveFolder).Chunk(CliConstants.CONTENT_SYNC_BATCH_SIZE).ToArray();
				foreach (string[] filesToReturn in returnBatches)
				{
					await Parallel.ForEachAsync(filesToReturn, (file, _) =>
					{
						try
						{
							string destFile = Path.Combine(contentFolder, Path.GetFileName(file));
					
							if (File.Exists(destFile))
								File.Replace(file, destFile, null);
							else
								File.Move(file, destFile);
						}
						catch (Exception ex)
						{
							Log.Error($"Failed to restore archived file '{file}': {ex.Message}");
						}

						return ValueTask.CompletedTask;
					});
					await Delay(50);
				}
				Directory.Delete(archiveFolder, true);
			}
			finally
			{
				lifecycle.MarkCancelCompleted();
			}
		}
		
		// Delete any files flagged for deletion, if any.
		for (int index = 0; index < contentToDelete.Length; index++)
		{
			await Delay(1);
			if (lifecycle.IsCancelled)
			{
				await ReturnArchivedFilesToManifest();
				throw new CliException($"Sync operation is cancelled.");
			}
			
			ContentFile c = contentToDelete[index];
			ContentProgressUpdateData contentProgress = new ContentProgressUpdateData
			{
				totalItems = totalItems, contentName = c.Id
			};

			try
			{
				// Move it to archive folder instead of deleting, this way we can revert if the operation is cancelled or if it had an error during moving process
				File.Move(c.LocalFilePath, Path.Combine(archiveFolder,  Path.GetFileName(c.LocalFilePath)));
			}
			catch (Exception exception)
			{
				contentProgress.EventType = ContentProgressUpdateData.EVT_TYPE_SyncError;
				contentProgress.errorMessage = exception.Message;
				onContentSyncProgressUpdate?.Invoke(contentProgress);
				await ReturnArchivedFilesToManifest();
				throw;
			}

			contentProgress.EventType = ContentProgressUpdateData.EVT_TYPE_SyncComplete;
			onContentSyncProgressUpdate?.Invoke(contentProgress);

			var updateProcessedItems = new ContentProgressUpdateData()
			{
				totalItems = totalItems,
				processedItems = (index + 1) + downloadedContent.Count,
				EventType = ContentProgressUpdateData.EVT_TYPE_UpdateProcessedItemCount
			};
			onContentSyncProgressUpdate?.Invoke(updateProcessedItems);
		}
		await Delay(1);
		if (lifecycle.IsCancelled)
		{
			await ReturnArchivedFilesToManifest();
			throw new CliException($"Sync operation is cancelled.");
		}

		Directory.Delete(archiveFolder, true);

		var saveTasks = new List<Task>();
		foreach (var (c, j) in downloadedContent)
		{
			var contentFile = c;
			contentFile.Properties = j.GetProperty("properties");
			contentFile.Tags = JsonSerializer.SerializeToElement(c.ReferenceContent.tags);
			contentFile.FetchedFromManifestUid = targetManifestUid;
			saveTasks.Add(SaveContentFile(contentFolder, contentFile));
		}

		// Make the Up-to-Date content files reference the manifest to which we just synchronized.
		foreach (var c in contentToUpdateManifestReference)
		{
			var contentFile = c;
			// In some cases of conflict resolution the Reference Content could be null.
			if (c.ReferenceContent != null)
			{
				contentFile.Tags = JsonSerializer.SerializeToElement(c.ReferenceContent.tags);
			}
			contentFile.FetchedFromManifestUid = targetManifestUid;
			saveTasks.Add(SaveContentFile(contentFolder, contentFile));
		}

		// If any problem happens while we are saving to disk, let's undo the pull operation and log out the exceptions.
		try
		{
			await WhenAll(saveTasks);
			return report;
		}
		catch (Exception e)
		{
			// Let's just print out all the exceptions
			if (e is AggregateException ae)
			{
				foreach (var aeInnerException in ae.InnerExceptions)
				{
					Log.Fatal(aeInnerException, $"Error when saving content files. Undoing pull operation. EXCEPTION={aeInnerException}");
				}
			}
			else
			{
				Log.Fatal(e, $"Error when saving content files. Undoing pull operation. EXCEPTION={e}");
			}

			// If any content failed, we re-write undo all the changes by re-serializing all the local content that we had before we downloaded.
			// This makes the operation atomic.
			var undoPullTasks = contentToDownload.Union(contentToDelete)
				.Where(c => c.GetStatus().HasFlag(ContentStatus.Deleted) | c.GetStatus().HasFlag(ContentStatus.Modified))
				.Select(async contentFile =>
				{
					var fileName = Path.Combine(contentFolder, $"{contentFile.Id}.json");
					var fileContents = JsonSerializer.Serialize(contentFile, GetContentFileSerializationOptions());
					await File.WriteAllTextAsync(fileName, fileContents);
				}).ToArray();

			await WhenAll(undoPullTasks);

			throw new CliException("Something went wrong when synchronizing your local content. Please look at the logs for details.");
		}
		finally
		{
			_fileSystemOperationSemaphore.Release();
		}
	}

	public static void ComputeCorrectSyncOp(LocalContentFiles file, bool allowModifiedInAutoSync, bool allowDeletedInAutoSync, out HashSet<string> conflictedContent, out HashSet<string> canAutoSync,
		out HashSet<string> canUpdateReferenceToTargetWithoutDownload)
	{
		conflictedContent = new();
		canAutoSync = new();
		canUpdateReferenceToTargetWithoutDownload = new();
		for (var i = 0; i < file.ContentFiles.Count; i++)
		{
			var contentFile = file.ContentFiles.ElementAt(i);

			var referenceContentFile = file.ReferenceManifests.TryGetValue(contentFile.FetchedFromManifestUid, out var m) ? contentFile.ChangeReference(m) : contentFile.ChangeReference(null);

			var statusAgainstTarget = contentFile.GetStatus();
			var statusAgainstReference = referenceContentFile.GetStatus();

			// A conflict occurs whenever all of these are true:
			// A. A local change existed against our reference manifest.
			var localChangeExisted = statusAgainstReference == ContentStatus.Modified;
			// B. The local changed content that we have does not match the one in the new target manifest
			var localChangeDoesNotMatch = statusAgainstTarget == ContentStatus.Modified;
			// C. There is a change between our reference manifest and the new target manifest.
			var wasChangedFromReference = localChangeExisted && localChangeDoesNotMatch &&
			                              contentFile.ReferenceContent.checksum.GetOrElse("") != referenceContentFile.ReferenceContent.checksum.GetOrElse("");

			// If all the above is true, this is a conflict.
			var wasConflict = localChangeExisted && localChangeDoesNotMatch && wasChangedFromReference;
			if (wasConflict)
			{
				conflictedContent.Add(contentFile.Id);
			}
			// If there was no conflict, we can decide whether we are allowed to download the content from the new target.
			else
			{
				// This happens when any one of these are true:
				// A. A local change had not been made against the reference manifest -- which means that we can fetch the new content if it is modified.
				var caseA = statusAgainstReference is ContentStatus.UpToDate && statusAgainstTarget is ContentStatus.Modified;
				// B. The content is deleted locally against our reference manifest AND there was a change between our reference manifest and the new target manifest.
				var caseB = allowDeletedInAutoSync && statusAgainstTarget is ContentStatus.Deleted;
				// C. If we want to syncModified and the status against target is modified
				var caseC = allowModifiedInAutoSync && statusAgainstTarget is ContentStatus.Modified;
				// If either of the above cases are true, we can auto-sync this content.
				if (caseA || caseB || caseC) canAutoSync.Add(contentFile.Id);

				// We also need to check if we can to update the reference manifest uid without downloading the content.
				// A. Our local content is up-to-date against the target AND it doesn't reference the target.
				var isManifestReferenceWrong = contentFile.FetchedFromManifestUid != file.TargetManifest.uid.GetOrElse("");
				caseA = statusAgainstTarget is ContentStatus.UpToDate && isManifestReferenceWrong;
				// B. Our local content has changes relative to our current reference AND it was not a conflict. 
				caseB = statusAgainstReference is ContentStatus.Modified && isManifestReferenceWrong;
				// C. Our local content does not exist in the reference manifest AND it was not a conflict (it just shows up as a creation now referencing the latest manifest) 
				caseC = statusAgainstReference is ContentStatus.Created && isManifestReferenceWrong;
				if (caseA || caseB || caseC) canUpdateReferenceToTargetWithoutDownload.Add(contentFile.Id);
			}
		}
	}

	/// <summary>
	/// Given a <see cref="LocalContentFiles"/> list, filters its content list based on some filter semantics.
	/// </summary>
	public static void FilterLocalContentFiles(ref LocalContentFiles file, string[] filters, ContentFilterType filterType)
	{
		Func<ContentFile, bool> filterFunc = BuildFilterFunc(filterType, filters);

		file.ContentFiles = file.ContentFiles.Where(filterFunc).ToList();
		file.PerIdContentFiles = file.ContentFiles.ToDictionary(f => f.Id, f => f);
	}

	/// <summary>
	/// <inheritdoc cref="AddTags(cli.Content.LocalContentFiles,string[])"/>
	/// </summary>
	public async Task AddTag(ContentFile f, string tag) =>
		await AddTags(new LocalContentFiles() { ContentFiles = new() { f }, PerIdContentFiles = new() { { f.Id, f } }, TargetManifest = null, }, new[] { tag });

	/// <summary>
	/// <inheritdoc cref="AddTags(cli.Content.LocalContentFiles,string[])"/>
	/// </summary>
	public async Task AddTags(ContentFile f, string[] tags) =>
		await AddTags(new LocalContentFiles() { ContentFiles = new() { f }, PerIdContentFiles = new() { { f.Id, f } }, TargetManifest = null, }, tags);

	/// <summary>
	/// Adds the given tags to each content file in the list of <see cref="LocalContentFiles"/>.
	///
	/// If <paramref name="addDuplicates"/> is false, we will only add tags to the files that don't already have that tag.
	/// Otherwise, it'll add it again.
	/// </summary>
	public async Task AddTags(LocalContentFiles localContentFiles, string[] tags)
	{
		// The caller of this function must ensure that a reset has happened at least once in this realm (hence the assert)
		var contentFolder = EnsureContentPathForRealmExists(out var created, _requester.Pid, localContentFiles.ManifestId);
		Debug.Assert(!created, "This should never happen. If does, this is a bug --- please report it to Beamable.");

		var saveTasks = new List<Task>();
		foreach (var contentFile in localContentFiles.ContentFiles)
		{
			var f = contentFile;

			var existingTags = f.GetTagsArray();
			var newTags = existingTags.Union(tags);

			f.Tags = JsonSerializer.SerializeToElement(newTags);
			saveTasks.Add(SaveContentFile(contentFolder, f));
		}

		await WhenAll(saveTasks);
	}
	
	/// <summary>
	/// Set the given tags to each content file in the list of <see cref="LocalContentFiles"/>.
	/// it will replace all the tags in the content.
	/// </summary>
	public async Task SetTags(LocalContentFiles localContentFiles, string[] tags)
	{
		// The caller of this function must ensure that a reset has happened at least once in this realm (hence the assert)
		var contentFolder = EnsureContentPathForRealmExists(out var created, _requester.Pid, localContentFiles.ManifestId);
		Debug.Assert(!created, "This should never happen. If does, this is a bug --- please report it to Beamable.");

		var saveTasks = new List<Task>();
		foreach (var contentFile in localContentFiles.ContentFiles)
		{
			var f = contentFile;
			
			// Override the tags with the new tags
			f.Tags = JsonSerializer.SerializeToElement(tags);
			
			saveTasks.Add(SaveContentFile(contentFolder, f));
		}

		await WhenAll(saveTasks);
	}

	/// <summary>
	/// <inheritdoc cref="Beamable.Api.Autogenerated.Models.RemoveTags"/>
	/// </summary>
	public async Task RemoveTag(ContentFile f, string tag) =>
		await RemoveTags(new LocalContentFiles() { ContentFiles = new() { f }, PerIdContentFiles = new() { { f.Id, f } }, TargetManifest = null, }, new[] { tag });

	/// <summary>
	/// <inheritdoc cref="Beamable.Api.Autogenerated.Models.RemoveTags"/>
	/// </summary>
	public async Task RemoveTags(ContentFile f, string[] tags) =>
		await RemoveTags(new LocalContentFiles() { ContentFiles = new() { f }, PerIdContentFiles = new() { { f.Id, f } }, TargetManifest = null, }, tags);

	/// <summary>
	/// Removes the given tags to each content file in the list of <paramref name="localContentFiles"/>.
	///
	/// When <paramref name="maxRemoveCount"/> is 0, we'll remove every instance of that tag from the list of tags.
	/// If its any value ABOVE 0, we'll remove only that many instances of the tags from the list of content.
	/// </summary>
	public async Task RemoveTags(LocalContentFiles localContentFiles, string[] tags)
	{
		// The caller of this function must ensure that a reset has happened at least once in this realm (hence the assert)
		var contentFolder = EnsureContentPathForRealmExists(out var created, _requester.Pid, localContentFiles.ManifestId);
		Debug.Assert(!created, "This should never happen. If does, this is a bug --- please report it to Beamable.");

		var saveTasks = new List<Task>();
		foreach (var contentFile in localContentFiles.ContentFiles)
		{
			var f = contentFile;

			var existingTags = f.GetTagsArray().ToList();
			var newTags = existingTags.Except(tags);

			f.Tags = JsonSerializer.SerializeToElement(newTags);
			saveTasks.Add(SaveContentFile(contentFolder, f));
		}

		await WhenAll(saveTasks);
	}

	/// <summary>
	/// Utility function that saves the given <see cref="ContentFile"/> to the given folder.
	/// </summary>
	public async Task SaveContentFile(string contentFolder, ContentFile f)
	{
		try
		{
			var fileName = Path.Combine(contentFolder, $"{f.Id}.json");
			SortContentProperties(ref f);
			var fileContents = JsonSerializer.Serialize(f, GetContentFileSerializationOptions());
			await File.WriteAllTextAsync(fileName, fileContents);
		}
		catch(Exception exception)
		{
			Console.WriteLine(exception.Message);
		}
	}

	public static void SortContentProperties(ref ContentFile f)
	{
		var editable = JsonSerializer.SerializeToNode(f.Properties)!.AsObject();
		var newSortedProps = new List<KeyValuePair<string, JsonNode>>(editable.Count);

		foreach (var kvp in editable.OrderBy(kvp => kvp.Key)) newSortedProps.Add(kvp);
		foreach (var kvp in newSortedProps) editable.Remove(kvp.Key);
		foreach (var kvp in newSortedProps) editable.Add(kvp.Key, kvp.Value);

		f.Properties = JsonSerializer.Deserialize<JsonElement>(editable.ToJsonString(), GetContentFileSerializationOptions());
	}

	/// <summary>
	/// Returns the expected path for the content id. Also makes sure it exists.
	/// </summary>
	public string GetPathForContentId(string contentId, string manifestId = "global")
	{
		var contentFolder = EnsureContentPathForRealmExists(out var created, _requester.Pid, manifestId);
		Debug.Assert(!created, "This should never happen. If does, this is a bug --- please report it to Beamable.");
		return Path.Combine(contentFolder, $"{contentId}.json");
	}

	/// <summary>
	/// Helper utility that converts a collection of <see cref="ContentFile"/>s to the public
	/// <see cref="LocalContentManifestEntry"/> format.
	/// </summary>
	public static IEnumerable<LocalContentManifestEntry> ContentFileToLocalContentManifestEntries(IEnumerable<ContentFile> files)
	{
		return files.Select(file =>
		{
			var tags = file.Tags.EnumerateArray().Select(ae => ae.GetString() ?? "").ToArray();
			var tagStatus = file.GetTagStatus();
			return new LocalContentManifestEntry()
			{
				FullId = file.Id,
				TypeName = GetContentType(file),
				Name = GetContentName(file),
				Hash = file.PropertiesChecksum,
				Tags = tags,
				TagsStatus = tags.Select(t => (int)tagStatus[t]).ToArray(),
				CurrentStatus = (int)file.GetStatus(),
				IsInConflict = file.IsInConflict,
				JsonFilePath = file.LocalFilePath,
				ReferenceManifestUid = file.FetchedFromManifestUid,
			};
		});
	}

	/// <summary>
	/// Serializes just the <see cref="ContentFile.Properties"/> object.
	/// We need this because we compute checksums ignoring tags.
	/// </summary>
	public static string SerializeProperties(ContentFile file)
	{
		SortContentProperties(ref file);
		return JsonSerializer.Serialize(file.Properties, GetContentFileSerializationOptions(false));
	}

	/// <summary>
	/// Our ContentId is a '.'-separated string whose final component is a name and the substring before it, its type hierarchy.
	/// This extracts the substring representing the Content Type hierarchy for this object. 
	/// </summary>
	public static string GetContentType(in ContentFile file) => file.Id[..file.Id.LastIndexOf('.')];

	/// <summary>
	/// <inheritdoc cref="GetContentType(in cli.Content.ContentFile)"/>
	/// </summary>
	public static string GetContentType(in string contentId) => contentId[..contentId.LastIndexOf('.')];

	/// <summary>
	/// Our ContentId is a '.'-separated string whose final component is a name and the substring before it, its type hierarchy.
	/// This extracts the substring representing the content's name. 
	/// </summary>
	public static string GetContentName(in ContentFile file) => GetContentName(file.Id);

	/// <summary>
	/// <inheritdoc cref="GetContentName(in cli.Content.ContentFile)"/> 
	/// </summary>
	public static string GetContentName(in string contentId) => contentId[(contentId.LastIndexOf('.') + 1)..];

	/// <summary>
	/// Computes the SHA1 checksum we use for content-file diff'ing by hashing the serialized <see cref="ContentFile.Properties"/>.
	/// Serialization of the properties must use <see cref="GetContentFileSerializationOptions"/> (with indent as false)  to ensure field ordering. 
	/// </summary>
	public static string CalculateChecksum(in ContentFile file) => CalculateChecksum(SerializeProperties(file));

	/// <summary>
	/// <inheritdoc cref="CalculateChecksum(in cli.Content.ContentFile)"/> 
	/// </summary>
	public static string CalculateChecksum(string propertiesJsonWithoutIndent)
	{
		var bytes = Encoding.UTF8.GetBytes(propertiesJsonWithoutIndent);
		var hash = SHA1.HashData(bytes);
		var checksum = Convert.ToHexString(hash).ToLower();
		return checksum;
	}

	/// <summary>
	/// This returns a <see cref="JsonSerializerOptions"/> that will correctly serialize a <see cref="ContentFile"/>.
	/// </summary>
	public static JsonSerializerOptions GetContentFileSerializationOptions(bool indent = true)
	{
		return new JsonSerializerOptions() { WriteIndented = indent, IncludeFields = true };
	}

	public async Task<bool> ContentExistByIds(string[] contentIds)
	{
		var localFiles = await GetAllContentFiles(filterType: ContentFilterType.ExactIds, filters: contentIds, getLocalStateOnly: true);
		return localFiles.ContentFiles.Select(c => c.Id).Intersect(contentIds).Count() == contentIds.Length;
	}

	/// <summary>
	/// This gets and caches the manifest with the given Id and UID. If a blank UID is provided, this will fetch the latest manifest (the latest manifest is un-cacheable).
	/// </summary>
	public async Task<ClientManifestJsonResponse> GetManifest(string manifestId = "global", string manifestUid = "", bool cachedOnly = false, bool replaceLatest = false)
	{
		// Realms don't have a content manifest by default, so... until the first publish happens, we assume dummy response and a fake UID as the realm manifest.
		// This dummy manifest can only ever be found when asking for it specifically OR trying to fetch the latest manifest.
		// We DO NOT return this when asking for specific manifestUid ('cause this could explode our conflict resolution in all sorts of different ways)
		if (manifestUid == FAKE_EMPTY_MANIFEST_UID)
			return CreateFakeEmptyManifest();

		var cacheKey = GetCacheKeyForManifest(_requester.Cid, _requester.Pid, manifestId, manifestUid);
		var latestCacheKey = GetCacheKeyForLatestManifest(_requester.Cid, _requester.Pid, manifestId);

		// If we are getting setting a new latest manifest, clear it from the cache.
		if (replaceLatest)
			_cachedManifests.Remove(latestCacheKey, out _);

		if (!_cachedManifests.TryGetValue(cacheKey, out var manifest) && !cachedOnly)
		{
			if (string.IsNullOrEmpty(manifestUid))
			{
				try
				{
					manifest = await _contentApi.GetManifestPublicJson(manifestId);
				}
				catch (RequesterException e)
				{
					if (e.Status == 404 && e.Message.Contains("Unable to load the requested manifest."))
					{
						return CreateFakeEmptyManifest();
					}

					throw;
				}

				var specificCacheKey = GetCacheKeyForManifest(_requester.Cid, _requester.Pid, manifestId, manifest.uid.GetOrElse(""));
				_cachedManifests[specificCacheKey] = manifest;

				// We cache, with the key of an empty string, the latest manifest.
				_cachedManifests[latestCacheKey] = manifest;
			}
			else
			{
				_cachedManifests[cacheKey] = manifest = await _contentApi.GetManifestPublicJson(manifestId, manifestUid);
			}
		}

		// On certain cases, we want to replace a fetched manifest as the one mapped to the "latest" manifest in the cache map.
		// For example, in "ListenToRemoteContentPublishes", we fetch a new manifest whenever a new publish happens which, by definition, means "latest" has changed.
		// So... the GetManifest call we do there, has this replaceLatest flag.
		if (replaceLatest)
			_cachedManifests[latestCacheKey] = manifest;

		return manifest;
	}

	/// <summary>
	/// This gets and caches the email associated with the given account id.
	/// </summary>
	private async Task<string> GetAccountEmail(long accountId)
	{
		if (accountId == 0) return "";
		if (_cachedAccountEmails.TryGetValue(accountId, out var email))
		{
			return email;
		}

		_cachedAccountEmails[accountId] = email = await _accountsApi
			.GetFind(accountId.ToString())
			.Map(res => res.email.GetOrElse(""));
		return email;
	}

	/// <summary>
	/// Creates a filter function based on the filter type.
	/// Throws an exception if an unsupported filter in a specific callsite is given. 
	/// </summary>
	private static Func<ContentFile, bool> BuildFilterFunc(ContentFilterType filterType, string[] filters)
	{
		Func<ContentFile, bool> filterFunc;
		switch (filterType)
		{
			case ContentFilterType.ExactIds:
			{
				filterFunc = f => filters.Length == 0 || filters.Any(id => id == f.Id);
				break;
			}
			case ContentFilterType.TypeHierarchy:
			{
				filterFunc = f => filters.Length == 0 || filters.Any(contentType => f.Id.StartsWith(contentType));
				break;
			}
			case ContentFilterType.TypeHierarchyStrict:
			{
				filterFunc = f => filters.Length == 0 || filters.Any(contentType => GetContentType(in f) == contentType);
				break;
			}
			case ContentFilterType.Regexes:
			{
				var regexes = filters.Select(f => new Regex(f, RegexOptions.Compiled)).ToArray();
				filterFunc = f => filters.Length == 0 || regexes.Any(r => r.IsMatch(f.Id));
				break;
			}
			case ContentFilterType.Tags:
			{
				filterFunc = f => filters.Length == 0 || f.GetTagsArray().Intersect(filters).Any();
				break;
			}
			default:
				throw new CliException($"Filter not supported {filterType}");
		}

		return filterFunc;
	}


	/// <summary>
	/// Realms don't have a content manifest by default, so... until the first publish happens, we assume dummy response and a fake UID as the realm manifest.
	/// This dummy manifest can only ever be found when asking for it specifically OR trying to fetch the latest manifest.
	/// We DO NOT return this when asking for specific manifestUid ('cause this could explode our conflict resolution in all sorts of different ways)
	/// </summary>
	private static ClientManifestJsonResponse CreateFakeEmptyManifest()
	{
		return new ClientManifestJsonResponse() { uid = FAKE_EMPTY_MANIFEST_UID, entries = Array.Empty<ClientContentInfoJson>(), publisherAccountId = new(), };
	}
}

[CliContractType]
public class ContentSyncReport
{
	public string ManifestId;

	public string[] ConflictingContents;
	public string[] AutoSynchedContents;
	public string[] ReferenceUpdatedContents;
	public string[] DeletedCreatedContents;
}

/// <summary>
/// Helper struct built by <see cref="ContentService.GetAllContentFiles"/> that represents a "local manifest in relation to a published manifest".
/// </summary>
public struct LocalContentFiles
{
	public string ManifestId;
	public ClientManifestJsonResponse TargetManifest;
	public List<ContentFile> ContentFiles;
	public Dictionary<string, ContentFile> PerIdContentFiles;
	public HashSet<string> ReferenceManifestUids;
	public Dictionary<string, ClientManifestJsonResponse> ReferenceManifests;
}

[Serializable]
public struct ContentFile : IEquatable<ContentFile>
{
	public const string JSON_NAME_PROPERTIES = "properties";
	public const string JSON_NAME_TAGS = "tags";
	public const string JSON_NAME_REFERENCE_MANIFEST_ID = "referenceManifestId";

	[JsonIgnore] public string Id;
	[JsonIgnore] public string LocalFilePath;
	[JsonIgnore] public string PropertiesChecksum;
	[JsonIgnore] public ClientContentInfoJson ReferenceContent;
	[JsonIgnore] public bool IsInConflict;
	[JsonIgnore] public bool CanAutoSync;
	[JsonIgnore] public bool CanUpdateReferenceWithTarget;

	[JsonPropertyName(JSON_NAME_PROPERTIES)]
	public JsonElement Properties;

	[JsonPropertyName(JSON_NAME_TAGS)] public JsonElement Tags;

	[JsonPropertyName(JSON_NAME_REFERENCE_MANIFEST_ID)]
	public string FetchedFromManifestUid;


	public ContentStatus GetStatus()
	{
		ContentStatus ret;
		if (ReferenceContent == null) ret = ContentStatus.Created;
		else if (string.IsNullOrEmpty(LocalFilePath) || !File.Exists(LocalFilePath)) ret = ContentStatus.Deleted;
		else if (ReferenceContent.checksum != PropertiesChecksum || IsTagsDiff()) ret = ContentStatus.Modified;
		else ret = ContentStatus.UpToDate;
		return ret;
	}

	public ContentFile ChangeReference(ClientManifestJsonResponse newReferenceManifest)
	{
		var copy = this;
		copy.ReferenceContent = newReferenceManifest == null ? null : newReferenceManifest.entries.FirstOrDefault(j => j.contentId == copy.Id);
		copy.FetchedFromManifestUid = newReferenceManifest != null ? newReferenceManifest.uid : copy.FetchedFromManifestUid;
		return copy;
	}

	public string[] GetTagsArray() => Tags.EnumerateArray().Select(f => f.GetString()).ToArray();

	public bool IsTagsDiff()
	{
		var status = GetTagStatus();
		return status.Count != status.Values.Count(s => s is TagStatus.LocalAndRemote);
	}

	public string GetStatusString()
	{
		var status = GetStatus();
		var applyPrefix = IsInConflict;
		var prefix = applyPrefix ? "[red]conflict[/] - " : "";
		if (status.HasFlag(ContentStatus.Created)) return $"{prefix}[green]created[/]";
		if (status.HasFlag(ContentStatus.Deleted)) return $"{prefix}[red]deleted[/]";
		if (status.HasFlag(ContentStatus.Modified)) return $"{prefix}[yellow]modified[/]";
		if (status.HasFlag(ContentStatus.UpToDate)) return $"{prefix}up to date";

		throw new ArgumentOutOfRangeException(nameof(GetStatus), GetStatus(), null);
	}

	public Dictionary<string, TagStatus> GetTagStatus()
	{
		var remoteTags = ReferenceContent?.tags ?? Array.Empty<string>();
		var localTags = Tags.EnumerateArray().Select(j => j.GetString()).ToArray();

		var remoteOnlyTags = remoteTags.Except(localTags);
		var localOnlyTags = localTags.Except(remoteTags);
		var bothTags = localTags.Intersect(remoteTags);

		var res = new Dictionary<string, TagStatus>();
		foreach (var t in bothTags) res.Add(t, TagStatus.LocalAndRemote);
		foreach (var t in remoteOnlyTags) res.Add(t, TagStatus.RemoteOnly);
		foreach (var t in localOnlyTags) res.Add(t, TagStatus.LocalOnly);

		return res;
	}

	public bool Equals(ContentFile other) => Id == other.Id;

	public override bool Equals(object obj) => obj is ContentFile other && Equals(other);

	public override int GetHashCode() => (Id != null ? Id.GetHashCode() : 0);

	public static bool operator ==(ContentFile left, ContentFile right) => left.Equals(right);

	public static bool operator !=(ContentFile left, ContentFile right) => !left.Equals(right);
}

public class ContentProgressUpdateData
{
	/// <summary>
	/// The engine integration is expected throw an error that the specific content could not be reverted and stop the process.
	/// </summary>
	public const int EVT_TYPE_SyncError = 0;
	
	/// <summary>
	/// The engine integration is expected to update the progress bar with the current item that was synced.
	/// </summary>
	public const int EVT_TYPE_SyncComplete = 1;

	/// <summary>
	/// The engine integration is expected to update the progress bar with the current item that was published.
	/// </summary>
	public const int EVT_TYPE_PublishComplete = 2;
	
	/// <summary>
	/// The engine integration is expected to update the progress bar progress percentage with the new value.
	/// </summary>
	public const int EVT_TYPE_UpdateProcessedItemCount = 3;
	

	/// <summary>
	/// One of <see cref="EVT_TYPE_SyncComplete"/>, <see cref="EVT_TYPE_SyncCompleted"/> or <see cref="EVT_TYPE_SyncError"/>.
	/// The semantics of each field are defined based on the event and documented on these comments.
	/// </summary>
	public int EventType;

	public string contentName;

	public string errorMessage;

	public int totalItems;

	public int processedItems;
}
